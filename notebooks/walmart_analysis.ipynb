{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart Sales Data Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook provides a comprehensive analysis of Walmart sales data to identify trends, seasonality, and product performance patterns.\n",
    "\n",
    "### Dataset Information\n",
    "- **Source**: Walmart Recruiting - Store Sales Forecasting (Kaggle)\n",
    "- **Period**: February 2010 to November 2012\n",
    "- **Stores**: 45 Walmart stores across different regions\n",
    "- **Departments**: 99 departments per store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "db_path = '../data/walmart_sales.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "print(f\"Connected to database: {db_path}\")\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_sql_query(\"SELECT * FROM train\", conn)\n",
    "stores = pd.read_sql_query(\"SELECT * FROM stores\", conn)\n",
    "features = pd.read_sql_query(\"SELECT * FROM features\", conn)\n",
    "\n",
    "# Convert date columns\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Stores dataset shape: {stores.shape}\")\n",
    "print(f\"Features dataset shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== TRAIN DATASET INFO ===\")\n",
    "print(train.info())\n",
    "print(\"\\n=== TRAIN DATASET DESCRIPTION ===\")\n",
    "print(train.describe())\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== KEY STATISTICS ===\")\n",
    "print(f\"Total records: {len(train):,}\")\n",
    "print(f\"Unique stores: {train['Store'].nunique()}\")\n",
    "print(f\"Unique departments: {train['Dept'].nunique()}\")\n",
    "print(f\"Date range: {train['Date'].min()} to {train['Date'].max()}\")\n",
    "print(f\"Total sales: ${train['Weekly_Sales'].sum():,.2f}\")\n",
    "print(f\"Average weekly sales: ${train['Weekly_Sales'].mean():,.2f}\")\n",
    "print(f\"Negative sales count: {(train['Weekly_Sales'] < 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sales Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "# Monthly sales trends\n",
    "monthly_sales = train.groupby(train['Date'].dt.to_period('M')).agg({\n",
    "    'Weekly_Sales': ['sum', 'mean', 'count'],\n",
    "    'Store': 'nunique',\n",
    "    'Dept': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "monthly_sales.columns = ['Total_Sales', 'Avg_Sales', 'Record_Count', 'Active_Stores', 'Active_Depts']\n",
    "monthly_sales.index = monthly_sales.index.to_timestamp()\n",
    "\n",
    "print(\"Monthly Sales Summary:\")\n",
    "print(monthly_sales.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot monthly sales trends\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total monthly sales\n",
    "ax1.plot(monthly_sales.index, monthly_sales['Total_Sales'], marker='o', linewidth=2)\n",
    "ax1.set_title('Total Monthly Sales Trend', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Total Sales ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average weekly sales\n",
    "ax2.plot(monthly_sales.index, monthly_sales['Avg_Sales'], marker='s', color='orange', linewidth=2)\n",
    "ax2.set_title('Average Weekly Sales Trend', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Average Sales ($)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Yearly comparison\n",
    "yearly_sales = train.groupby(train['Date'].dt.year)['Weekly_Sales'].sum()\n",
    "ax3.bar(yearly_sales.index, yearly_sales.values, color='skyblue', alpha=0.8)\n",
    "ax3.set_title('Total Sales by Year', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Total Sales ($)')\n",
    "ax3.set_xlabel('Year')\n",
    "\n",
    "# Quarterly trends\n",
    "quarterly_sales = train.groupby([train['Date'].dt.year, train['Date'].dt.quarter])['Weekly_Sales'].sum()\n",
    "quarters = [f\"{year}-Q{quarter}\" for year, quarter in quarterly_sales.index]\n",
    "ax4.plot(range(len(quarterly_sales)), quarterly_sales.values, marker='d', color='green', linewidth=2)\n",
    "ax4.set_title('Quarterly Sales Trend', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Total Sales ($)')\n",
    "ax4.set_xlabel('Quarter')\n",
    "ax4.set_xticks(range(0, len(quarters), 2))\n",
    "ax4.set_xticklabels([quarters[i] for i in range(0, len(quarters), 2)], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Store Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train data with store information\n",
    "train_stores = train.merge(stores, on='Store')\n",
    "\n",
    "# Top performing stores\n",
    "top_stores = train_stores.groupby(['Store', 'Type', 'Size']).agg({\n",
    "    'Weekly_Sales': ['sum', 'mean', 'count'],\n",
    "    'Dept': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "top_stores.columns = ['Total_Sales', 'Avg_Sales', 'Record_Count', 'Dept_Count']\n",
    "top_stores = top_stores.sort_values('Total_Sales', ascending=False)\n",
    "\n",
    "print(\"Top 15 Performing Stores:\")\n",
    "print(top_stores.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store performance by type\n",
    "store_type_performance = train_stores.groupby('Type').agg({\n",
    "    'Store': 'nunique',\n",
    "    'Weekly_Sales': ['sum', 'mean'],\n",
    "    'Size': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "store_type_performance.columns = ['Store_Count', 'Total_Sales', 'Avg_Sales', 'Avg_Size']\n",
    "\n",
    "print(\"Store Performance by Type:\")\n",
    "print(store_type_performance)\n",
    "\n",
    "# Visualize store performance by type\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Total sales by store type\n",
    "ax1.bar(store_type_performance.index, store_type_performance['Total_Sales'], \n",
    "        color=['skyblue', 'lightcoral', 'lightgreen'][:len(store_type_performance)])\n",
    "ax1.set_title('Total Sales by Store Type', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Total Sales ($)')\n",
    "ax1.set_xlabel('Store Type')\n",
    "\n",
    "# Average sales by store type\n",
    "ax2.bar(store_type_performance.index, store_type_performance['Avg_Sales'], \n",
    "        color=['skyblue', 'lightcoral', 'lightgreen'][:len(store_type_performance)])\n",
    "ax2.set_title('Average Sales by Store Type', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Average Sales ($)')\n",
    "ax2.set_xlabel('Store Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Department Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department performance analysis\n",
    "dept_performance = train.groupby('Dept').agg({\n",
    "    'Weekly_Sales': ['sum', 'mean', 'std', 'count'],\n",
    "    'Store': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "dept_performance.columns = ['Total_Sales', 'Avg_Sales', 'Sales_Std', 'Record_Count', 'Store_Count']\n",
    "dept_performance['CV'] = (dept_performance['Sales_Std'] / dept_performance['Avg_Sales'] * 100).round(2)\n",
    "dept_performance = dept_performance.sort_values('Total_Sales', ascending=False)\n",
    "\n",
    "print(\"Top 20 Performing Departments:\")\n",
    "print(dept_performance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top departments\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top 15 departments by total sales\n",
    "top_15_depts = dept_performance.head(15)\n",
    "ax1.barh(range(len(top_15_depts)), top_15_depts['Total_Sales'], color='steelblue')\n",
    "ax1.set_yticks(range(len(top_15_depts)))\n",
    "ax1.set_yticklabels([f\"Dept {idx}\" for idx in top_15_depts.index])\n",
    "ax1.set_title('Top 15 Departments by Total Sales', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Total Sales ($)')\n",
    "\n",
    "# Department sales distribution\n",
    "ax2.hist(dept_performance['Total_Sales'], bins=20, color='lightcoral', alpha=0.7)\n",
    "ax2.set_title('Distribution of Department Total Sales', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Total Sales ($)')\n",
    "ax2.set_ylabel('Number of Departments')\n",
    "\n",
    "# Most consistent departments (lowest CV)\n",
    "most_consistent = dept_performance[dept_performance['Record_Count'] >= 100].sort_values('CV').head(15)\n",
    "ax3.barh(range(len(most_consistent)), most_consistent['CV'], color='lightgreen')\n",
    "ax3.set_yticks(range(len(most_consistent)))\n",
    "ax3.set_yticklabels([f\"Dept {idx}\" for idx in most_consistent.index])\n",
    "ax3.set_title('Most Consistent Departments (Lowest Variability)', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Coefficient of Variation (%)')\n",
    "\n",
    "# Average sales by department (top 15)\n",
    "top_15_avg = dept_performance.head(15)\n",
    "ax4.bar(range(len(top_15_avg)), top_15_avg['Avg_Sales'], color='gold')\n",
    "ax4.set_xticks(range(len(top_15_avg)))\n",
    "ax4.set_xticklabels([f\"D{idx}\" for idx in top_15_avg.index], rotation=45)\n",
    "ax4.set_title('Average Sales - Top 15 Departments', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Average Sales ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality patterns\n",
    "# Monthly patterns\n",
    "monthly_pattern = train.groupby(train['Date'].dt.month).agg({\n",
    "    'Weekly_Sales': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "monthly_pattern.columns = ['Total_Sales', 'Avg_Sales', 'Record_Count']\n",
    "monthly_pattern.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "print(\"Monthly Sales Patterns:\")\n",
    "print(monthly_pattern)\n",
    "\n",
    "# Day of week patterns\n",
    "train['DayOfWeek'] = train['Date'].dt.day_name()\n",
    "dow_pattern = train.groupby('DayOfWeek')['Weekly_Sales'].agg(['sum', 'mean', 'count']).round(2)\n",
    "dow_pattern.columns = ['Total_Sales', 'Avg_Sales', 'Record_Count']\n",
    "\n",
    "# Reorder days\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_pattern = dow_pattern.reindex(day_order)\n",
    "\n",
    "print(\"\\nDay of Week Patterns:\")\n",
    "print(dow_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize seasonality\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Monthly sales pattern\n",
    "ax1.plot(monthly_pattern.index, monthly_pattern['Avg_Sales'], marker='o', linewidth=3, markersize=8)\n",
    "ax1.set_title('Average Sales by Month', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Average Sales ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Day of week pattern\n",
    "ax2.bar(dow_pattern.index, dow_pattern['Avg_Sales'], color='lightcoral')\n",
    "ax2.set_title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Average Sales ($)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Holiday impact\n",
    "holiday_impact = train.groupby('IsHoliday')['Weekly_Sales'].agg(['mean', 'count']).round(2)\n",
    "holiday_impact.columns = ['Avg_Sales', 'Record_Count']\n",
    "holiday_impact.index = ['Non-Holiday', 'Holiday']\n",
    "\n",
    "ax3.bar(holiday_impact.index, holiday_impact['Avg_Sales'], color=['lightblue', 'orange'])\n",
    "ax3.set_title('Sales Impact: Holiday vs Non-Holiday', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Average Sales ($)')\n",
    "\n",
    "# Quarterly trend\n",
    "quarterly_trend = train.groupby([train['Date'].dt.year, train['Date'].dt.quarter])['Weekly_Sales'].mean()\n",
    "quarters_labels = [f\"{year}-Q{quarter}\" for year, quarter in quarterly_trend.index]\n",
    "\n",
    "ax4.plot(range(len(quarterly_trend)), quarterly_trend.values, marker='s', linewidth=2, markersize=6)\n",
    "ax4.set_title('Average Sales by Quarter', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Average Sales ($)')\n",
    "ax4.set_xlabel('Quarter')\n",
    "ax4.set_xticks(range(0, len(quarters_labels), 2))\n",
    "ax4.set_xticklabels([quarters_labels[i] for i in range(0, len(quarters_labels), 2)], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nHoliday Impact:\")\n",
    "print(holiday_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving averages and trends\n",
    "weekly_sales_total = train.groupby('Date')['Weekly_Sales'].sum().reset_index()\n",
    "weekly_sales_total = weekly_sales_total.sort_values('Date')\n",
    "\n",
    "# Calculate moving averages\n",
    "weekly_sales_total['MA_4_weeks'] = weekly_sales_total['Weekly_Sales'].rolling(window=4).mean()\n",
    "weekly_sales_total['MA_8_weeks'] = weekly_sales_total['Weekly_Sales'].rolling(window=8).mean()\n",
    "weekly_sales_total['MA_12_weeks'] = weekly_sales_total['Weekly_Sales'].rolling(window=12).mean()\n",
    "\n",
    "# Plot moving averages\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(weekly_sales_total['Date'], weekly_sales_total['Weekly_Sales'], \n",
    "         alpha=0.5, label='Weekly Sales', linewidth=1)\n",
    "plt.plot(weekly_sales_total['Date'], weekly_sales_total['MA_4_weeks'], \n",
    "         label='4-Week MA', linewidth=2)\n",
    "plt.plot(weekly_sales_total['Date'], weekly_sales_total['MA_8_weeks'], \n",
    "         label='8-Week MA', linewidth=2)\n",
    "plt.plot(weekly_sales_total['Date'], weekly_sales_total['MA_12_weeks'], \n",
    "         label='12-Week MA', linewidth=2)\n",
    "\n",
    "plt.title('Sales Trends with Moving Averages', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Weekly Sales ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Merge with features data\n",
    "train_features = train.merge(features, on=['Store', 'Date'], how='left')\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = ['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "correlation_data = train_features[numeric_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Sales vs External Factors', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation with Weekly Sales:\")\n",
    "sales_correlations = correlation_data['Weekly_Sales'].sort_values(ascending=False)\n",
    "for factor, corr in sales_correlations.items():\n",
    "    if factor != 'Weekly_Sales':\n",
    "        print(f\"{factor:.<20} {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"=\" * 60)\n",
    "print(\"WALMART SALES ANALYSIS - KEY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Overall Performance\n",
    "total_sales = train['Weekly_Sales'].sum()\n",
    "avg_weekly_sales = train['Weekly_Sales'].mean()\n",
    "print(f\"\\n1. OVERALL PERFORMANCE\")\n",
    "print(f\"   Total Sales: ${total_sales:,.2f}\")\n",
    "print(f\"   Average Weekly Sales: ${avg_weekly_sales:,.2f}\")\n",
    "print(f\"   Analysis Period: {train['Date'].min()} to {train['Date'].max()}\")\n",
    "\n",
    "# 2. Top Performers\n",
    "best_store = top_stores.index[0][0]\n",
    "best_dept = dept_performance.index[0]\n",
    "print(f\"\\n2. TOP PERFORMERS\")\n",
    "print(f\"   Best Store: Store {best_store} (${top_stores.iloc[0]['Total_Sales']:,.2f})\")\n",
    "print(f\"   Best Department: Dept {best_dept} (${dept_performance.iloc[0]['Total_Sales']:,.2f})\")\n",
    "print(f\"   Best Store Type: {store_type_performance.index[0]}\")\n",
    "\n",
    "# 3. Seasonal Patterns\n",
    "best_month = monthly_pattern.idxmax()['Avg_Sales']\n",
    "worst_month = monthly_pattern.idxmin()['Avg_Sales']\n",
    "print(f\"\\n3. SEASONAL PATTERNS\")\n",
    "print(f\"   Peak Sales Month: {best_month}\")\n",
    "print(f\"   Lowest Sales Month: {worst_month}\")\n",
    "print(f\"   Holiday Impact: {holiday_impact.loc['Holiday', 'Avg_Sales'] - holiday_impact.loc['Non-Holiday', 'Avg_Sales']:+.2f}\")\n",
    "\n",
    "# 4. Store Analysis\n",
    "print(f\"\\n4. STORE ANALYSIS\")\n",
    "print(f\"   Total Stores: {train['Store'].nunique()}\")\n",
    "print(f\"   Store Types: {stores['Type'].nunique()} ({', '.join(stores['Type'].unique())})\")\n",
    "print(f\"   Average Store Size: {stores['Size'].mean():,.0f} sq ft\")\n",
    "\n",
    "# 5. Department Analysis\n",
    "consistent_dept = dept_performance[dept_performance['Record_Count'] >= 100].sort_values('CV').index[0]\n",
    "volatile_dept = dept_performance[dept_performance['Record_Count'] >= 100].sort_values('CV', ascending=False).index[0]\n",
    "print(f\"\\n5. DEPARTMENT ANALYSIS\")\n",
    "print(f\"   Total Departments: {train['Dept'].nunique()}\")\n",
    "print(f\"   Most Consistent Dept: {consistent_dept} (CV: {dept_performance.loc[consistent_dept, 'CV']:.1f}%)\")\n",
    "print(f\"   Most Volatile Dept: {volatile_dept} (CV: {dept_performance.loc[volatile_dept, 'CV']:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Analysis completed successfully!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key results to CSV files\n",
    "import os\n",
    "\n",
    "# Create exports directory\n",
    "exports_dir = '../reports'\n",
    "os.makedirs(exports_dir, exist_ok=True)\n",
    "\n",
    "# Export summaries\n",
    "top_stores.to_csv(f'{exports_dir}/top_stores_performance.csv')\n",
    "dept_performance.to_csv(f'{exports_dir}/department_performance.csv')\n",
    "monthly_pattern.to_csv(f'{exports_dir}/monthly_sales_patterns.csv')\n",
    "store_type_performance.to_csv(f'{exports_dir}/store_type_performance.csv')\n",
    "\n",
    "print(\"Results exported to CSV files:\")\n",
    "print(f\"- {exports_dir}/top_stores_performance.csv\")\n",
    "print(f\"- {exports_dir}/department_performance.csv\")\n",
    "print(f\"- {exports_dir}/monthly_sales_patterns.csv\")\n",
    "print(f\"- {exports_dir}/store_type_performance.csv\")\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"\\nDatabase connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
